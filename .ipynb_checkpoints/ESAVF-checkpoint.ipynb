{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA with Verbal Fluency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESA FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dasem.semantic import Semantic\n",
    "import numpy as np\n",
    "from io import open\n",
    "import collections\n",
    "from itertools import compress, groupby\n",
    "import math\n",
    "import time\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define misc variables\n",
    "ID = \"0001\"\n",
    "textfile = \"test2.txt\"\n",
    "home_path = \"/Users/au183362/Documents/postdoc/Parkinson-DBS/Eira_Aksnes/\"\n",
    "file_path = join(home_path, 'raw', textfile)\n",
    "save_path = join(home_path, 'output')\n",
    "\n",
    "iterations = 30000 # input to Semantic-module\n",
    "\n",
    "#From Yund et al.:\n",
    "#ESA switch threshold is \"PercentRESA * MeanAllESA\" or the (Minimum sequence ESA)+0.00001 \n",
    "#so that there is at least one ESA switch.\n",
    "PercentRESA = 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from DASEM, semantic relatedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example:\n",
    "\n",
    "  >>> semantic = Semantic(30000)  # and wait\n",
    "    >>> semantic.relatedness(['hund', 'kat', 'mus', 'fisk']).round(3)\n",
    "    array([[ 1.   ,  0.022,  0.005,  0.001],\n",
    "           [ 0.022,  1.   ,  0.002,  0.   ],\n",
    "           [ 0.005,  0.002,  1.   ,  0.01 ],\n",
    "           [ 0.001,  0.   ,  0.01 ,  1.   ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-22 22:04:23,957 - __main__ - INFO - Downloading https://dumps.wikimedia.org/dawiki/latest/dawiki-latest-pages-articles.xml.bz2 to /Users/au183362/dasem_data/wikipedia/dawiki-latest-pages-articles.xml.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!python -m dasem.wikipedia download --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603.078813791\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "#On Eira's macbook:\n",
    "#Both Semantic(300) and Semantic(30) = 600-700 sec ≈ 10-12 min\n",
    "#On AH's macbook: Semantic(30000) = 500-535 sec ≈ 8-9 min\n",
    "semantic = Semantic(iterations)\n",
    "\n",
    "elapsed = time.time()-t\n",
    "print(elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Mus\n",
      "1: Ko\n",
      "2: Hest\n",
      "3: Gris\n",
      "4: Elefant\n",
      "5: Kat\n",
      "6: Pindsvin\n",
      "7: Krage\n",
      "8: Måge\n",
      "9: Fugl\n",
      "10: Mosegris\n",
      "11: Ørentvist\n",
      "12: Flue\n",
      "13: Elefant\n",
      "14: Næsehorn\n",
      "15: Løve\n",
      "16: Tiger\n",
      "17: Bjørn\n",
      "18: Æsel\n",
      "19: Hest\n",
      "20: Krokodille\n",
      "21: Næsehorn\n",
      "22: Løve\n",
      "23: Kat\n",
      "24: Rotte\n"
     ]
    }
   ],
   "source": [
    "inputs = [line.rstrip() for line in open(file_path)]\n",
    "for i, inp in enumerate(inputs):\n",
    "    print(u\"{0:d}: {1:s}\".format(i, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mus  Ko  Hest  Gris  Elefant  Kat  Pindsvin  Krage  Måge  Fugl  Mosegris  Ørentvist\n",
      "[[1.    0.005 0.002 0.003 0.003 0.01  0.007 0.004 0.001 0.01  0.004 0.   ]\n",
      " [0.005 1.    0.003 0.006 0.005 0.004 0.    0.001 0.    0.001 0.    0.   ]\n",
      " [0.002 0.003 1.    0.003 0.011 0.003 0.    0.    0.    0.004 0.    0.   ]\n",
      " [0.003 0.006 0.003 1.    0.002 0.003 0.003 0.009 0.    0.005 0.    0.   ]\n",
      " [0.003 0.005 0.011 0.002 1.    0.003 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.01  0.004 0.003 0.003 0.003 1.    0.001 0.001 0.    0.004 0.001 0.   ]\n",
      " [0.007 0.    0.    0.003 0.001 0.001 1.    0.007 0.001 0.002 0.001 0.   ]\n",
      " [0.004 0.001 0.    0.009 0.001 0.001 0.007 1.    0.002 0.015 0.001 0.   ]\n",
      " [0.001 0.    0.    0.    0.    0.    0.001 0.002 1.    0.033 0.    0.   ]\n",
      " [0.01  0.001 0.004 0.005 0.002 0.004 0.002 0.015 0.033 1.    0.001 0.   ]\n",
      " [0.004 0.    0.    0.    0.    0.001 0.001 0.001 0.    0.001 1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.01  0.002 0.001 0.    0.001 0.001 0.    0.003 0.    0.002 0.    0.003]\n",
      " [0.003 0.005 0.011 0.002 1.    0.003 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.001 0.004 0.    0.019 0.001 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.    0.007 0.001 0.008 0.002 0.    0.    0.    0.003 0.    0.   ]\n",
      " [0.    0.001 0.004 0.002 0.007 0.002 0.    0.    0.    0.001 0.    0.001]\n",
      " [0.006 0.001 0.004 0.001 0.001 0.002 0.    0.001 0.001 0.002 0.    0.   ]\n",
      " [0.004 0.002 0.038 0.001 0.017 0.002 0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.002 0.003 1.    0.003 0.011 0.003 0.    0.    0.    0.004 0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.004 0.    0.003 0.    0.    0.005 0.    0.   ]\n",
      " [0.001 0.001 0.004 0.    0.019 0.001 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.    0.007 0.001 0.008 0.002 0.    0.    0.    0.003 0.    0.   ]\n",
      " [0.01  0.004 0.003 0.003 0.003 1.    0.001 0.001 0.    0.004 0.001 0.   ]\n",
      " [0.025 0.001 0.002 0.005 0.002 0.004 0.001 0.014 0.002 0.005 0.015 0.003]]\n",
      "\n",
      "\n",
      "Flue  Elefant  Næsehorn  Løve  Tiger  Bjørn  Æsel  Hest  Krokodille  Næsehorn  Løve  Kat\n",
      "[[0.01  0.003 0.001 0.001 0.    0.006 0.004 0.002 0.001 0.001 0.001 0.01 ]\n",
      " [0.002 0.005 0.001 0.    0.001 0.001 0.002 0.003 0.    0.001 0.    0.004]\n",
      " [0.001 0.011 0.004 0.007 0.004 0.004 0.038 1.    0.    0.004 0.007 0.003]\n",
      " [0.    0.002 0.    0.001 0.002 0.001 0.001 0.003 0.    0.    0.001 0.003]\n",
      " [0.001 1.    0.019 0.008 0.007 0.001 0.017 0.011 0.004 0.019 0.008 0.003]\n",
      " [0.001 0.003 0.001 0.002 0.002 0.002 0.002 0.003 0.    0.001 0.002 1.   ]\n",
      " [0.    0.001 0.001 0.    0.    0.    0.    0.    0.003 0.001 0.    0.001]\n",
      " [0.003 0.001 0.001 0.    0.    0.001 0.    0.    0.    0.001 0.    0.001]\n",
      " [0.    0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.002 0.002 0.002 0.003 0.001 0.002 0.001 0.004 0.005 0.002 0.003 0.004]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.001]\n",
      " [0.003 0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    0.001 0.002 0.    0.001 0.002 0.    0.001 0.    0.002 0.    0.001]\n",
      " [0.001 1.    0.019 0.008 0.007 0.001 0.017 0.011 0.004 0.019 0.008 0.003]\n",
      " [0.002 0.019 1.    0.004 0.002 0.    0.    0.004 0.002 1.    0.004 0.001]\n",
      " [0.    0.008 0.004 1.    0.014 0.003 0.007 0.007 0.003 0.004 1.    0.002]\n",
      " [0.001 0.007 0.002 0.014 1.    0.001 0.006 0.004 0.001 0.002 0.014 0.002]\n",
      " [0.002 0.001 0.    0.003 0.001 1.    0.002 0.004 0.    0.    0.003 0.002]\n",
      " [0.    0.017 0.    0.007 0.006 0.002 1.    0.038 0.    0.    0.007 0.002]\n",
      " [0.001 0.011 0.004 0.007 0.004 0.004 0.038 1.    0.    0.004 0.007 0.003]\n",
      " [0.    0.004 0.002 0.003 0.001 0.    0.    0.    1.    0.002 0.003 0.   ]\n",
      " [0.002 0.019 1.    0.004 0.002 0.    0.    0.004 0.002 1.    0.004 0.001]\n",
      " [0.    0.008 0.004 1.    0.014 0.003 0.007 0.007 0.003 0.004 1.    0.002]\n",
      " [0.001 0.003 0.001 0.002 0.002 0.002 0.002 0.003 0.    0.001 0.002 1.   ]\n",
      " [0.    0.002 0.    0.001 0.003 0.    0.    0.002 0.003 0.    0.001 0.004]]\n",
      "\n",
      "\n",
      "Rotte\n",
      "[[0.025]\n",
      " [0.001]\n",
      " [0.002]\n",
      " [0.005]\n",
      " [0.002]\n",
      " [0.004]\n",
      " [0.001]\n",
      " [0.014]\n",
      " [0.002]\n",
      " [0.005]\n",
      " [0.015]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.002]\n",
      " [0.   ]\n",
      " [0.001]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.002]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.001]\n",
      " [0.004]\n",
      " [1.   ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ESA_table = semantic.relatedness(inputs).round(3)\n",
    "#print(raw_ESA_table[:,0])\n",
    "for i in range(int(math.ceil((len(inputs)/12.)))):\n",
    "    print(\"  \".join(map(unicode,inputs[12*i:12*(i+1)])))\n",
    "    print(ESA_table[:,12*i:12*(i+1)])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant ID: 0001\n",
      "\n",
      "Total number of \n",
      "words: 25\n",
      "corrects: 20\n",
      "duplicates: 5\n",
      "unknowns: 0\n"
     ]
    }
   ],
   "source": [
    "#Total number of words (animals), correct, duplicates, and unknowns\n",
    "N_Totl = len(inputs)\n",
    "N_Uniq = len(np.unique(inputs))\n",
    "N_Dups = len([dupl for dupl in collections.Counter(inputs).values() if dupl>1])\n",
    "N_UNKN = sum([np.isnan(unk).all() for unk in ESA_table])\n",
    "\n",
    "print(\"Participant ID: {0:s}\".format(ID))\n",
    "print(\"\\nTotal number of \\nwords: {0:d}\\ncorrects: {1:d}\" \n",
    "      \"\\nduplicates: {2:d}\\nunknowns: {3:d}\".format(N_Totl, N_Uniq, N_Dups, N_UNKN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mus-Ko = 0.005\n",
      "Ko-Hest = 0.003\n",
      "Hest-Gris = 0.003\n",
      "Gris-Elefant = 0.002\n",
      "Elefant-Kat = 0.003\n",
      "Kat-Pindsvin = 0.001\n",
      "Pindsvin-Krage = 0.007\n",
      "Krage-Måge = 0.002\n",
      "Måge-Fugl = 0.033\n",
      "Fugl-Mosegris = 0.001\n",
      "Mosegris-Ørentvist = 0.000\n",
      "Ørentvist-Flue = 0.003\n",
      "Flue-Elefant = 0.001\n",
      "Elefant-Næsehorn = 0.019\n",
      "Næsehorn-Løve = 0.004\n",
      "Løve-Tiger = 0.014\n",
      "Tiger-Bjørn = 0.001\n",
      "Bjørn-Æsel = 0.002\n",
      "Æsel-Hest = 0.038\n",
      "Hest-Krokodille = 0.000\n",
      "Krokodille-Næsehorn = 0.002\n",
      "Næsehorn-Løve = 0.004\n",
      "Løve-Kat = 0.002\n",
      "Kat-Rotte = 0.004\n",
      "\n",
      "Mean (chronological pairwise) ESA for Participant ID 0001: 0.006\n"
     ]
    }
   ],
   "source": [
    "#Extract ESA values for continuous (i.e., chronological) pairs\n",
    "ESA = []\n",
    "DictESA = {}\n",
    "SumESA = 0.0\n",
    "\n",
    "for n, i in enumerate(inputs):     \n",
    "    if n > 0:\n",
    "        print(u\"{0:s}-{1:s} = {2:2.3f}\".format(inputs[n-1], i, ESA_table[n, n-1]))\n",
    "        OneESA = ESA_table[n, n-1]\n",
    "        DictESA[u\"{0:s}-{1:s}\".format(inputs[n-1], i)] = OneESA \n",
    "        ESA = ESA + [OneESA]\n",
    "        #ESA.append(OneESA)\n",
    "        SumESA = SumESA + OneESA\n",
    "\n",
    "MeanESA = SumESA / len(ESA)\n",
    "\n",
    "print(\"\\nMean (chronological pairwise) ESA for Participant ID {0:s}: {1:2.3f}\".format(ID, MeanESA.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean All ESA for Participant ID 0001: 0.020\n",
      "\n",
      "SOI Participant ID 0001: 0.327\n"
     ]
    }
   ],
   "source": [
    "#Extract ESA values for all possible pairs (still mainly clumsy Yund-code, but it works)\n",
    "DictAllESA = {}\n",
    "N_AllESA = 0\n",
    "SumAllESA = 0.0\n",
    "\n",
    "for i in range(len(inputs)-1):\n",
    "    for j in range(i+1, len(inputs)):\n",
    "            OneESA = ESA_table[i,j]\n",
    "            DictAllESA[u\"{0:s}-{1:s}\".format(inputs[i], inputs[j])] = OneESA\n",
    "            N_AllESA = N_AllESA + 1\n",
    "            SumAllESA = SumAllESA + OneESA\n",
    "        \n",
    "if (N_AllESA == 0):\n",
    "    MeanAllESA = 0.0\n",
    "    SOI = 0.0\n",
    "else:\n",
    "    MeanAllESA = SumAllESA / N_AllESA\n",
    "    if MeanAllESA == 0.0:\n",
    "        SOI = 0.0\n",
    "    else:\n",
    "        SOI = MeanESA / MeanAllESA\n",
    "\n",
    "#print(inputs)\n",
    "#print(ESA_table)\n",
    "#print(DictAllESA)\n",
    "print(\"\\nMean All ESA for Participant ID {0:s}: {1:2.3f}\".format(ID, MeanAllESA.round(3)))\n",
    "print(\"\\nSOI Participant ID {0:s}: {1:2.3f}\".format(ID, SOI.round(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters and switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014719999999999974\n"
     ]
    }
   ],
   "source": [
    "# Setting the ESA_Threshold\n",
    "ESAsort = sorted(ESA) # creating a sorted copy of ESA\n",
    "ESA_Threshold = PercentRESA * MeanAllESA  # ESA switch if ESA < ESA_Threshold\n",
    "if ESA_Threshold < ESAsort[0]:\n",
    "    ESA_Threshold = ESAsort[0] + 0.000001\n",
    "print(ESA_Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of switches: 21\n",
      "Number of clusters: 3\n",
      "\n",
      "Switch index:\n",
      "1: Mus\n",
      "1: Ko\n",
      "1: Hest\n",
      "1: Gris\n",
      "1: Elefant\n",
      "1: Kat\n",
      "1: Pindsvin\n",
      "1: Krage\n",
      "0: Måge\n",
      "1: Fugl\n",
      "1: Mosegris\n",
      "1: Ørentvist\n",
      "1: Flue\n",
      "0: Elefant\n",
      "1: Næsehorn\n",
      "1: Løve\n",
      "1: Tiger\n",
      "1: Bjørn\n",
      "0: Æsel\n",
      "1: Hest\n",
      "1: Krokodille\n",
      "1: Næsehorn\n",
      "1: Løve\n",
      "1: Kat\n"
     ]
    }
   ],
   "source": [
    "#ESA switches\n",
    "ESAsw = [int(esa<ESA_Threshold) for esa in ESA]\n",
    "\n",
    "ESAswCount = collections.Counter(ESAsw).most_common() # counting the ones and the zeros of the switch-vector\n",
    "\n",
    "if 1 in ESAswCount[0]:\n",
    "    sumESAsw = ESAswCount[0][1] # assigning the count of ones to sumESAsw (2nd element of 1st tuple)\n",
    "    NumCS = ESAswCount[1][1] # assigning the count of zeros to sumESAsw (2nd element of 2nd tuple)\n",
    "elif 0 in ESAswCount[0]:\n",
    "    sumESAsw = ESAswCount[1][1] # assigning the count of ones to sumESAsw (2nd element of 2nd tuple)\n",
    "    NumCS = ESAswCount[0][1] # assigning the count of zeros to sumESAsw (2nd element of 1st tuple)\n",
    "\n",
    "print(\"Number of switches: {0:d}\\nNumber of clusters: {1:d}\\n\".format(sumESAsw, NumCs))\n",
    "#print(\"  \".join(map(unicode,inputs)))\n",
    "print(\"Switch index:\")\n",
    "\n",
    "for sw, i in zip(ESAsw, inputs):\n",
    "    print(u\"{0:d}: {1:s}\".format(sw, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes: [2, 2, 2]\n",
      "Accumulated cluster size: 6\n",
      "All 'clusters': [1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "SizeCS = [sum(1 for _ in g)+1 for _, g in groupby(ESAsw) if _==0] # we add one to each cluster-sum for 1st word in the cluster\n",
    "SumCS = sum(SizeCS)\n",
    "print(\"Cluster sizes: {}\".format(\"\".join(str(SizeCS))))\n",
    "print(\"Accumulated cluster size: {}\".format(SumCS))\n",
    "\n",
    "ESAcs = ESAsw[:]\n",
    "count = 0\n",
    "#[ESAcs.insert(i, SizeCS[count]) for i, sw in enumerate(ESAsw)]   \n",
    "for i, sw in enumerate(ESAsw):\n",
    "    if sw == 0:\n",
    "        ESAcs[i] = SizeCS[count]\n",
    "        ESAcs[i+1:i+SizeCS[count]] = np.tile(0, SizeCS[count]-1)\n",
    "        count = count + 1\n",
    "print(\"All 'clusters': {}\".format(\"\".join(str(ESAcs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/save output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15L"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create output file for each subject (.txt)\n",
    "#NB! not all entries in the below code are relevant for our current analysis\n",
    "\n",
    "#create/open file for writing output\n",
    "outfile = open(join(save_path, ID +'_out.txt'), 'w')\n",
    "\n",
    "#summary values\n",
    "outfile.write(u'Number of animals:   ')\n",
    "outfile.write(format(N_Totl, u'>3d'))\n",
    "outfile.write(u'\\nNumber correct:      ')\n",
    "outfile.write(format(N_Uniq, u'>3d'))\n",
    "outfile.write(u'\\nRepetitions:        ')\n",
    "outfile.write(format(N_Dups, u'>3d'))\n",
    "outfile.write(u'\\nUnknown Animals:    ')\n",
    "outfile.write(format(N_UNKN, u'>3d'))\n",
    "\n",
    "#ESA analysis\n",
    "outfile.write(u'\\n\\nSequence Mean ESA:  ')\n",
    "outfile.write(format(MeanESA, u'10.4f'))\n",
    "outfile.write(u'\\nTotal Mean ESA:     ')\n",
    "outfile.write(format(MeanAllESA, u'10.4f'))\n",
    "outfile.write(u'\\nSem Org Index (SOI):')\n",
    "outfile.write(format(SOI, u'10.4f'))\n",
    "outfile.write(u'\\n\\nESA switches:       ')\n",
    "outfile.write(format(sum(ESAsw), u'>4d'))\n",
    "outfile.write(u'  (')\n",
    "outfile.write(format(N_Totl/sumESAsw, u'5.2f'))\n",
    "outfile.write(u' words/switch)')\n",
    "outfile.write(u'\\n\\nESA clustes:        ')\n",
    "outfile.write(format(NumCS, u'>4d'))\n",
    "\n",
    "outfile.write(u'  (')\n",
    "outfile.write(format(SumCS/NumCS, u'5.2f'))\n",
    "outfile.write(u' words/cluster)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:old]",
   "language": "python",
   "name": "conda-env-old-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
