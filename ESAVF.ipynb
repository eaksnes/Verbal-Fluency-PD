{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA with Verbal Fluency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESA FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named dill",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8b1517291da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named dill"
     ]
    }
   ],
   "source": [
    "from dasem.semantic import Semantic\n",
    "import numpy as np\n",
    "from io import open\n",
    "import collections\n",
    "from itertools import compress, groupby\n",
    "import math\n",
    "import time\n",
    "from os.path import join\n",
    "import pickle\n",
    "import dill\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.25, 35.15625, 39.0625, 42.96875, 46.875, 50.78125, 54.6875, 58.59375, 62.5, 66.40625]\n",
      "35.15625\n",
      "35.15625\n"
     ]
    }
   ],
   "source": [
    "test = [31.25, 35.15625, 39.0625, 42.96875, 46.875, 50.78125, 54.6875, 58.59375, 62.5, 66.40625]\n",
    "print(test)\n",
    "print(test[test > 35])\n",
    "test_mask = test[test > 35]\n",
    "print(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define misc variables\n",
    "ID = \"01\"\n",
    "textfile = \"id01.txt\"\n",
    "home_path = \"/Users/eiraaksnes/Documents/CFIN/\"\n",
    "file_path = join(home_path, 'raw_data', textfile)\n",
    "save_path = join(home_path, 'output')\n",
    "\n",
    "iterations = 30000 # input to Semantic-module\n",
    "\n",
    "#From Yund et al.:\n",
    "#ESA switch threshold is \"PercentRESA * MeanAllESA\" or the (Minimum sequence ESA)+0.00001 \n",
    "#so that there is at least one ESA switch.\n",
    "PercentRESA = 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from DASEM, semantic relatedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example:\n",
    "\n",
    "  >>> semantic = Semantic(30000)  # and wait\n",
    "    >>> semantic.relatedness(['hund', 'kat', 'mus', 'fisk']).round(3)\n",
    "    array([[ 1.   ,  0.022,  0.005,  0.001],\n",
    "           [ 0.022,  1.   ,  0.002,  0.   ],\n",
    "           [ 0.005,  0.002,  1.   ,  0.01 ],\n",
    "           [ 0.001,  0.   ,  0.01 ,  1.   ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB! Run the following cell only once! You're downloading all of the Danish wikipedia..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m dasem.wikipedia download --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB! The following cell may take somewhere between 6-12 mins to run, so be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644.5085031986237\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "#On Eira's macbook:\n",
    "#Both Semantic(300) and Semantic(30) = 600-700 sec ≈ 10-12 min\n",
    "#On AH's macbook: Semantic(30000) = 500-535 sec ≈ 8-9 min\n",
    "semantic = Semantic(iterations)\n",
    "\n",
    "elapsed = time.time()-t\n",
    "print(elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Mus\n",
      "1: Ko\n",
      "2: Hest\n",
      "3: Gris\n",
      "4: Elefant\n",
      "5: Kat\n",
      "6: Pindsvin\n",
      "7: Krage\n",
      "8: Måge\n",
      "9: Fugl\n",
      "10: Mosegris\n",
      "11: Ørentvist\n",
      "12: Flue\n",
      "13: Elefant\n",
      "14: Næsehorn\n",
      "15: Løve\n",
      "16: Tiger\n",
      "17: Bjørn\n",
      "18: Æsel\n",
      "19: Hest\n",
      "20: Krokodille\n",
      "21: Næsehorn\n",
      "22: Løve\n",
      "23: Kat\n",
      "24: Rotte\n"
     ]
    }
   ],
   "source": [
    "inputs = [line.rstrip() for line in open(file_path)]\n",
    "for i, inp in enumerate(inputs):\n",
    "    print(u\"{0:d}: {1:s}\".format(i, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NB! The following cell is made in order to differentiate between python 2 and 3 use. (unicode replaced with str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureUtf(s):\n",
    "  try:\n",
    "      if type(s) == unicode:\n",
    "        return ensureUtf('ignore')\n",
    "  except: \n",
    "    return str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mus  Ko  Hest  Gris  Elefant  Kat  Pindsvin  Krage  Måge  Fugl  Mosegris  Ørentvist\n",
      "[[1.    0.005 0.002 0.003 0.003 0.01  0.008 0.004 0.001 0.01  0.004 0.   ]\n",
      " [0.005 1.    0.003 0.006 0.005 0.004 0.    0.001 0.    0.001 0.    0.   ]\n",
      " [0.002 0.003 1.    0.003 0.011 0.003 0.    0.    0.    0.004 0.    0.   ]\n",
      " [0.003 0.006 0.003 1.    0.002 0.003 0.003 0.009 0.    0.005 0.    0.   ]\n",
      " [0.003 0.005 0.011 0.002 1.    0.003 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.01  0.004 0.003 0.003 0.003 1.    0.001 0.001 0.    0.004 0.001 0.   ]\n",
      " [0.008 0.    0.    0.003 0.001 0.001 1.    0.007 0.001 0.002 0.001 0.   ]\n",
      " [0.004 0.001 0.    0.009 0.001 0.001 0.007 1.    0.002 0.015 0.001 0.   ]\n",
      " [0.001 0.    0.    0.    0.    0.    0.001 0.002 1.    0.033 0.    0.   ]\n",
      " [0.01  0.001 0.004 0.005 0.002 0.004 0.002 0.015 0.033 1.    0.001 0.   ]\n",
      " [0.004 0.    0.    0.    0.    0.001 0.001 0.001 0.    0.001 1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.011 0.003 0.001 0.    0.001 0.001 0.    0.003 0.    0.002 0.    0.003]\n",
      " [0.003 0.005 0.011 0.002 1.    0.003 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.001 0.004 0.    0.02  0.002 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.001 0.007 0.001 0.009 0.002 0.    0.    0.    0.003 0.    0.   ]\n",
      " [0.    0.001 0.004 0.002 0.007 0.002 0.    0.    0.    0.001 0.    0.001]\n",
      " [0.006 0.001 0.004 0.001 0.001 0.002 0.    0.001 0.001 0.002 0.    0.   ]\n",
      " [0.004 0.002 0.038 0.001 0.017 0.002 0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.002 0.003 1.    0.003 0.011 0.003 0.    0.    0.    0.004 0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.005 0.    0.003 0.    0.    0.005 0.    0.   ]\n",
      " [0.001 0.001 0.004 0.    0.02  0.002 0.001 0.001 0.    0.002 0.    0.   ]\n",
      " [0.001 0.001 0.007 0.001 0.009 0.002 0.    0.    0.    0.003 0.    0.   ]\n",
      " [0.01  0.004 0.003 0.003 0.003 1.    0.001 0.001 0.    0.004 0.001 0.   ]\n",
      " [0.025 0.001 0.002 0.005 0.002 0.004 0.001 0.014 0.002 0.005 0.015 0.003]]\n",
      "\n",
      "\n",
      "Flue  Elefant  Næsehorn  Løve  Tiger  Bjørn  Æsel  Hest  Krokodille  Næsehorn  Løve  Kat\n",
      "[[0.011 0.003 0.001 0.001 0.    0.006 0.004 0.002 0.001 0.001 0.001 0.01 ]\n",
      " [0.003 0.005 0.001 0.001 0.001 0.001 0.002 0.003 0.    0.001 0.001 0.004]\n",
      " [0.001 0.011 0.004 0.007 0.004 0.004 0.038 1.    0.    0.004 0.007 0.003]\n",
      " [0.    0.002 0.    0.001 0.002 0.001 0.001 0.003 0.    0.    0.001 0.003]\n",
      " [0.001 1.    0.02  0.009 0.007 0.001 0.017 0.011 0.005 0.02  0.009 0.003]\n",
      " [0.001 0.003 0.002 0.002 0.002 0.002 0.002 0.003 0.    0.002 0.002 1.   ]\n",
      " [0.    0.001 0.001 0.    0.    0.    0.    0.    0.003 0.001 0.    0.001]\n",
      " [0.003 0.001 0.001 0.    0.    0.001 0.    0.    0.    0.001 0.    0.001]\n",
      " [0.    0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.002 0.002 0.002 0.003 0.001 0.002 0.001 0.004 0.005 0.002 0.003 0.004]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.001]\n",
      " [0.003 0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    0.001 0.002 0.    0.002 0.002 0.    0.001 0.    0.002 0.    0.001]\n",
      " [0.001 1.    0.02  0.009 0.007 0.001 0.017 0.011 0.005 0.02  0.009 0.003]\n",
      " [0.002 0.02  1.    0.004 0.002 0.    0.    0.004 0.002 1.    0.004 0.002]\n",
      " [0.    0.009 0.004 1.    0.014 0.003 0.007 0.007 0.003 0.004 1.    0.002]\n",
      " [0.002 0.007 0.002 0.014 1.    0.001 0.006 0.004 0.001 0.002 0.014 0.002]\n",
      " [0.002 0.001 0.    0.003 0.001 1.    0.002 0.004 0.    0.    0.003 0.002]\n",
      " [0.    0.017 0.    0.007 0.006 0.002 1.    0.038 0.    0.    0.007 0.002]\n",
      " [0.001 0.011 0.004 0.007 0.004 0.004 0.038 1.    0.    0.004 0.007 0.003]\n",
      " [0.    0.005 0.002 0.003 0.001 0.    0.    0.    1.    0.002 0.003 0.   ]\n",
      " [0.002 0.02  1.    0.004 0.002 0.    0.    0.004 0.002 1.    0.004 0.002]\n",
      " [0.    0.009 0.004 1.    0.014 0.003 0.007 0.007 0.003 0.004 1.    0.002]\n",
      " [0.001 0.003 0.002 0.002 0.002 0.002 0.002 0.003 0.    0.002 0.002 1.   ]\n",
      " [0.    0.002 0.    0.    0.003 0.    0.    0.002 0.003 0.    0.    0.004]]\n",
      "\n",
      "\n",
      "Rotte\n",
      "[[0.025]\n",
      " [0.001]\n",
      " [0.002]\n",
      " [0.005]\n",
      " [0.002]\n",
      " [0.004]\n",
      " [0.001]\n",
      " [0.014]\n",
      " [0.002]\n",
      " [0.005]\n",
      " [0.015]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.002]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.002]\n",
      " [0.003]\n",
      " [0.   ]\n",
      " [0.   ]\n",
      " [0.004]\n",
      " [1.   ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ESA_table = semantic.relatedness(inputs).round(3)\n",
    "#print(raw_ESA_table[:,0])\n",
    "for i in range(int(math.ceil((len(inputs)/12.)))):\n",
    "    print(\"  \".join(map(str,inputs[12*i:12*(i+1)])))\n",
    "    print(ESA_table[:,12*i:12*(i+1)])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant ID: 0001\n",
      "\n",
      "Total number of \n",
      "words: 25\n",
      "corrects: 20\n",
      "duplicates: 5\n",
      "unknowns: 0\n"
     ]
    }
   ],
   "source": [
    "#Total number of words (animals), correct, duplicates, and unknowns\n",
    "N_Totl = len(inputs)\n",
    "N_Uniq = len(np.unique(inputs))\n",
    "N_Dups = len([dupl for dupl in collections.Counter(inputs).values() if dupl>1])\n",
    "N_UNKN = sum([np.isnan(unk).all() for unk in ESA_table])\n",
    "\n",
    "print(\"Participant ID: {0:s}\".format(ID))\n",
    "print(\"\\nTotal number of \\nwords: {0:d}\\ncorrects: {1:d}\" \n",
    "      \"\\nduplicates: {2:d}\\nunknowns: {3:d}\".format(N_Totl, N_Uniq, N_Dups, N_UNKN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mus-Ko = 0.005\n",
      "Ko-Hest = 0.003\n",
      "Hest-Gris = 0.003\n",
      "Gris-Elefant = 0.002\n",
      "Elefant-Kat = 0.003\n",
      "Kat-Pindsvin = 0.001\n",
      "Pindsvin-Krage = 0.007\n",
      "Krage-Måge = 0.002\n",
      "Måge-Fugl = 0.033\n",
      "Fugl-Mosegris = 0.001\n",
      "Mosegris-Ørentvist = 0.000\n",
      "Ørentvist-Flue = 0.003\n",
      "Flue-Elefant = 0.001\n",
      "Elefant-Næsehorn = 0.020\n",
      "Næsehorn-Løve = 0.004\n",
      "Løve-Tiger = 0.014\n",
      "Tiger-Bjørn = 0.001\n",
      "Bjørn-Æsel = 0.002\n",
      "Æsel-Hest = 0.038\n",
      "Hest-Krokodille = 0.000\n",
      "Krokodille-Næsehorn = 0.002\n",
      "Næsehorn-Løve = 0.004\n",
      "Løve-Kat = 0.002\n",
      "Kat-Rotte = 0.004\n",
      "\n",
      "Mean (chronological pairwise) ESA for Participant ID 0001: 0.006\n"
     ]
    }
   ],
   "source": [
    "#Extract ESA values for continuous (i.e., chronological) pairs\n",
    "ESA = []\n",
    "DictESA = {}\n",
    "SumESA = 0.0\n",
    "\n",
    "for n, i in enumerate(inputs):     \n",
    "    if n > 0:\n",
    "        print(u\"{0:s}-{1:s} = {2:2.3f}\".format(inputs[n-1], i, ESA_table[n, n-1]))\n",
    "        OneESA = ESA_table[n, n-1]\n",
    "        DictESA[u\"{0:s}-{1:s}\".format(inputs[n-1], i)] = OneESA \n",
    "        ESA = ESA + [OneESA]\n",
    "        #ESA.append(OneESA)\n",
    "        SumESA = SumESA + OneESA\n",
    "\n",
    "MeanESA = SumESA / len(ESA)\n",
    "\n",
    "print(\"\\nMean (chronological pairwise) ESA for Participant ID {0:s}: {1:2.3f}\".format(ID, MeanESA.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean All ESA for Participant ID 0001: 0.020\n",
      "\n",
      "SOI Participant ID 0001: 0.328\n"
     ]
    }
   ],
   "source": [
    "#Extract ESA values for all possible pairs (still mainly clumsy Yund-code, but it works)\n",
    "DictAllESA = {}\n",
    "N_AllESA = 0\n",
    "SumAllESA = 0.0\n",
    "\n",
    "for i in range(len(inputs)-1):\n",
    "    for j in range(i+1, len(inputs)):\n",
    "            OneESA = ESA_table[i,j]\n",
    "            DictAllESA[u\"{0:s}-{1:s}\".format(inputs[i], inputs[j])] = OneESA\n",
    "            N_AllESA = N_AllESA + 1\n",
    "            SumAllESA = SumAllESA + OneESA\n",
    "        \n",
    "if (N_AllESA == 0):\n",
    "    MeanAllESA = 0.0\n",
    "    SOI = 0.0\n",
    "else:\n",
    "    MeanAllESA = SumAllESA / N_AllESA\n",
    "    if MeanAllESA == 0.0:\n",
    "        SOI = 0.0\n",
    "    else:\n",
    "        SOI = MeanESA / MeanAllESA\n",
    "\n",
    "#print(inputs)\n",
    "#print(ESA_table)\n",
    "#print(DictAllESA)\n",
    "print(\"\\nMean All ESA for Participant ID {0:s}: {1:2.3f}\".format(ID, MeanAllESA.round(3)))\n",
    "print(\"\\nSOI Participant ID {0:s}: {1:2.3f}\".format(ID, SOI.round(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters and switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014764999999999966\n"
     ]
    }
   ],
   "source": [
    "# Setting the ESA_Threshold\n",
    "ESAsort = sorted(ESA) # creating a sorted copy of ESA\n",
    "ESA_Threshold = PercentRESA * MeanAllESA  # ESA switch if ESA < ESA_Threshold\n",
    "if ESA_Threshold < ESAsort[0]:\n",
    "    ESA_Threshold = ESAsort[0] + 0.000001\n",
    "print(ESA_Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of switches: 21\n",
      "Number of clusters: 3\n",
      "\n",
      "Switch index:\n",
      "1: Mus\n",
      "1: Ko\n",
      "1: Hest\n",
      "1: Gris\n",
      "1: Elefant\n",
      "1: Kat\n",
      "1: Pindsvin\n",
      "1: Krage\n",
      "0: Måge\n",
      "1: Fugl\n",
      "1: Mosegris\n",
      "1: Ørentvist\n",
      "1: Flue\n",
      "0: Elefant\n",
      "1: Næsehorn\n",
      "1: Løve\n",
      "1: Tiger\n",
      "1: Bjørn\n",
      "0: Æsel\n",
      "1: Hest\n",
      "1: Krokodille\n",
      "1: Næsehorn\n",
      "1: Løve\n",
      "1: Kat\n"
     ]
    }
   ],
   "source": [
    "#ESA switches\n",
    "ESAsw = [int(esa<ESA_Threshold) for esa in ESA]\n",
    "\n",
    "ESAswCount = collections.Counter(ESAsw).most_common() # counting the ones and the zeros of the switch-vector\n",
    "\n",
    "if 1 in ESAswCount[0]:\n",
    "    sumESAsw = ESAswCount[0][1] # assigning the count of ones to sumESAsw (2nd element of 1st tuple)\n",
    "    NumCS = ESAswCount[1][1] # assigning the count of zeros to NumCS (2nd element of 2nd tuple)\n",
    "elif 0 in ESAswCount[0]:\n",
    "    sumESAsw = ESAswCount[1][1] # assigning the count of ones to sumESAsw (2nd element of 2nd tuple)\n",
    "    NumCS = ESAswCount[0][1] # assigning the count of zeros to NumCS (2nd element of 1st tuple)\n",
    "\n",
    "print(\"Number of switches: {0:d}\\nNumber of clusters: {1:d}\\n\".format(sumESAsw, NumCS))\n",
    "#print(\"  \".join(map(unicode,inputs)))\n",
    "print(\"Switch index:\")\n",
    "\n",
    "for sw, i in zip(ESAsw, inputs):\n",
    "    print(u\"{0:d}: {1:s}\".format(sw, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes: [2, 2, 2]\n",
      "Accumulated cluster size: 6\n",
      "All 'clusters': [1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "SizeCS = [sum(1 for _ in g)+1 for _, g in groupby(ESAsw) if _==0] # we add one to each cluster-sum for 1st word in the cluster\n",
    "SumCS = sum(SizeCS)\n",
    "print(\"Cluster sizes: {}\".format(\"\".join(str(SizeCS))))\n",
    "print(\"Accumulated cluster size: {}\".format(SumCS))\n",
    "\n",
    "ESAcs = ESAsw[:]\n",
    "count = 0\n",
    "#[ESAcs.insert(i, SizeCS[count]) for i, sw in enumerate(ESAsw)]   \n",
    "for i, sw in enumerate(ESAsw):\n",
    "    if sw == 0:\n",
    "        ESAcs[i] = SizeCS[count]\n",
    "        ESAcs[i+1:i+SizeCS[count]] = np.tile(0, SizeCS[count]-1)\n",
    "        count = count + 1\n",
    "print(\"All 'clusters': {}\".format(\"\".join(str(ESAcs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/save output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create output file for each subject (.txt)\n",
    "#NB! not all entries in the below code are relevant for our current analysis\n",
    "\n",
    "#create/open file for writing output\n",
    "outfile = open(join(save_path, ID +'_out.txt'), 'w')\n",
    "\n",
    "#summary values\n",
    "outfile.write(u'Number of animals:   ')\n",
    "outfile.write(format(N_Totl, u'>3d'))\n",
    "outfile.write(u'\\nNumber correct:      ')\n",
    "outfile.write(format(N_Uniq, u'>3d'))\n",
    "outfile.write(u'\\nRepetitions:        ')\n",
    "outfile.write(format(N_Dups, u'>3d'))\n",
    "outfile.write(u'\\nUnknown Animals:    ')\n",
    "outfile.write(format(N_UNKN, u'>3d'))\n",
    "\n",
    "#ESA analysis\n",
    "outfile.write(u'\\n\\nSequence Mean ESA:  ')\n",
    "outfile.write(format(MeanESA, u'10.4f'))\n",
    "outfile.write(u'\\nTotal Mean ESA:     ')\n",
    "outfile.write(format(MeanAllESA, u'10.4f'))\n",
    "outfile.write(u'\\nSem Org Index (SOI):')\n",
    "outfile.write(format(SOI, u'10.4f'))\n",
    "outfile.write(u'\\n\\nESA switches:       ')\n",
    "outfile.write(format(sum(ESAsw), u'>4d'))\n",
    "outfile.write(u'  (')\n",
    "outfile.write(format(N_Totl/sumESAsw, u'5.2f'))\n",
    "outfile.write(u' words/switch)')\n",
    "outfile.write(u'\\n\\nESA clustes:        ')\n",
    "outfile.write(format(NumCS, u'>4d'))\n",
    "\n",
    "outfile.write(u'  (')\n",
    "outfile.write(format(SumCS/NumCS, u'5.2f'))\n",
    "outfile.write(u' words/cluster)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
